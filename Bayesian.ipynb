{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The related data and code are also been found on https://github.com/Xuanstar42/BERN02_Exercise3.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from scipy.signal import gaussian  \n",
    "except Exception:\n",
    "    from scipy.signal.windows import gaussian as _gaussian  \n",
    "    import scipy.signal as _sig\n",
    "    _sig.gaussian = _gaussian \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import bambi as bmb\n",
    "import arviz as az\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.patches import Patch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data Wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    reuse  total    group study\n",
      "0      74    211  control     1\n",
      "1     103    277  control     2\n",
      "2      77    135  control     3\n",
      "3      82    187  control     4\n",
      "4      21     25  control     5\n",
      "5     123    147  control     6\n",
      "6      28     30  control     7\n",
      "7      98    222   social     1\n",
      "8     587   1318   social     2\n",
      "9     406    655   social     3\n",
      "10    278    555   social     4\n",
      "11     21     24   social     5\n",
      "12    472    576   social     6\n",
      "13    101    132   social     7\n"
     ]
    }
   ],
   "source": [
    "# read in data\n",
    "data_file = \"towelData.csv\"\n",
    "data = pd.read_csv(data_file, sep=';', encoding='latin1')\n",
    "count = data.iloc[:, -1] # get the last column with numbers or yes/no\n",
    "\n",
    "# count has the number of yes and no for control and social norm groups\n",
    "control_yes = count[::4].to_numpy() # every 4th starting from 0 - control group + yes\n",
    "control_no = count[2::4].to_numpy() # every 4th starting from 2 - control group + no\n",
    "control_total = np.array([y + n for y, n in zip(control_yes, control_no)])\n",
    "\n",
    "social_yes = count[1::4].to_numpy() # every 4th starting from 1 - social norm group + yes\n",
    "social_no = count[3::4].to_numpy() # every 4th starting from 3 - social norm group + no\n",
    "social_total = np.array([y + n for y, n in zip(social_yes, social_no)])\n",
    "\n",
    "study = np.arange(1,len(control_yes)+1) # 7 diferent studies\n",
    "\n",
    "control_data = pd.DataFrame({\"reuse\": control_yes, \"total\": control_total, \"group\": \"control\", \"study\": study})\n",
    "social_data = pd.DataFrame({ \"reuse\": social_yes, \"total\": social_total, \"group\": \"social\", \"study\": study})\n",
    "\n",
    "combined_data = pd.concat([control_data, social_data], ignore_index=True)\n",
    "\n",
    "# Convert data types - important for bambi that they are correctly set \n",
    "# can give errors otherwise\n",
    "combined_data['reuse'] = combined_data['reuse'].astype(int)\n",
    "combined_data['total'] = combined_data['total'].astype(int)\n",
    "combined_data['group'] = combined_data['group'].astype('category')\n",
    "combined_data['study'] = combined_data['study'].astype('category')\n",
    "print(combined_data.head(25))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Apply bmb Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "       Formula: p(reuse, total) ~ 1 + group + (1|study)\n",
       "        Family: binomial\n",
       "          Link: p = logit\n",
       "  Observations: 14\n",
       "        Priors: \n",
       "    target = p\n",
       "        Common-level effects\n",
       "            Intercept ~ Normal(mu: 0.0, sigma: 3.5355)\n",
       "            group ~ Normal(mu: 0.0, sigma: 5.0)\n",
       "        \n",
       "        Group-level effects\n",
       "            1|study ~ Normal(mu: 0.0, sigma: HalfNormal(sigma: 3.5355))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_hierarchical = bmb.Model(\"p(reuse, total) ~ 1 + group + (1|study)\", combined_data, family=\"binomial\")\n",
    "model_hierarchical\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [Intercept, group, 1|study_sigma, 1|study_offset]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='8000' class='' max='8000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [8000/8000 00:15&lt;00:00 Sampling 4 chains, 22 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 15 seconds.\n",
      "There were 22 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The rhat statistic is larger than 1.01 for some parameters. This indicates problems during sampling. See https://arxiv.org/abs/1903.08008 for details\n",
      "The effective sample size per chain is smaller than 100 for some parameters.  A higher number is needed for reliable rhat and ess computation. See https://arxiv.org/abs/1903.08008 for details\n"
     ]
    }
   ],
   "source": [
    "idata_hierarchical = model_hierarchical.fit(random_seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It was found that there are too many divergences. Therefore, we need to modify the prior.\n",
    "\n",
    "# 4. Prior Modification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: [1|study_offset, 1|study_sigma, Intercept, group, p(reuse, total)]\n",
      "/var/folders/4s/2wy10by568x979b5g7g66m7c0000gn/T/ipykernel_37961/632727353.py:2: FutureWarning: extract_dataset has been deprecated, please use extract\n",
      "  prior = az.extract_dataset(idata_prior, group=\"prior_predictive\")[\"p(reuse, total)\"]\n"
     ]
    }
   ],
   "source": [
    "idata_prior = model_hierarchical.prior_predictive()\n",
    "prior = az.extract_dataset(idata_prior, group=\"prior_predictive\")[\"p(reuse, total)\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "       Formula: p(reuse, total) ~ 1 + group + (1|study)\n",
       "        Family: binomial\n",
       "          Link: p = logit\n",
       "  Observations: 14\n",
       "        Priors: \n",
       "    target = p\n",
       "        Common-level effects\n",
       "            Intercept ~ Normal(mu: 0.0, sigma: 1.0)\n",
       "            group ~ Normal(mu: 0.0, sigma: 5.0)\n",
       "        \n",
       "        Group-level effects\n",
       "            1|study ~ Normal(mu: 0.0, sigma: HalfNormal(sigma: 1.0))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "priors = {\n",
    "    \"Intercept\": bmb.Prior(\"Normal\", mu=0, sigma=1),\n",
    "    \"1|study\": bmb.Prior(\"Normal\", mu=0, sigma=bmb.Prior(\"HalfNormal\", sigma=1))\n",
    "}\n",
    "model_hierarchical = bmb.Model(\"p(reuse, total) ~ 1 + group + (1|study)\", combined_data, family=\"binomial\", priors=priors)\n",
    "model_hierarchical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Fitting Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [Intercept, group, 1|study_sigma, 1|study_offset]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='8000' class='' max='8000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [8000/8000 00:13&lt;00:00 Sampling 4 chains, 2 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 13 seconds.\n",
      "There were 2 divergences after tuning. Increase `target_accept` or reparameterize.\n"
     ]
    }
   ],
   "source": [
    "idata_hierarchical = model_hierarchical.fit(random_seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset> Size: 328kB\n",
      "Dimensions:            (chain: 4, draw: 1000, group_dim: 1, study__factor_dim: 7)\n",
      "Coordinates:\n",
      "  * chain              (chain) int64 32B 0 1 2 3\n",
      "  * draw               (draw) int64 8kB 0 1 2 3 4 5 ... 994 995 996 997 998 999\n",
      "  * group_dim          (group_dim) <U6 24B 'social'\n",
      "  * study__factor_dim  (study__factor_dim) <U1 28B '1' '2' '3' '4' '5' '6' '7'\n",
      "Data variables:\n",
      "    Intercept          (chain, draw) float64 32kB 0.1683 0.1897 ... 0.05734\n",
      "    group              (chain, draw, group_dim) float64 32kB 0.08793 ... 0.04418\n",
      "    1|study_sigma      (chain, draw) float64 32kB 1.052 1.137 ... 1.254 1.257\n",
      "    1|study            (chain, draw, study__factor_dim) float64 224kB -0.5754...\n",
      "Attributes:\n",
      "    created_at:                  2025-09-22T18:03:59.211093\n",
      "    arviz_version:               0.17.1\n",
      "    inference_library:           pymc\n",
      "    inference_library_version:   5.12.0\n",
      "    sampling_time:               13.24306583404541\n",
      "    tuning_steps:                1000\n",
      "    modeling_interface:          bambi\n",
      "    modeling_interface_version:  0.13.0\n"
     ]
    }
   ],
   "source": [
    "print(idata_hierarchical.posterior)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                mean     sd  hdi_5%  hdi_95%  mcse_mean  mcse_sd  ess_bulk  \\\n",
      "Intercept      0.381  0.355  -0.215    0.956      0.014    0.010     687.0   \n",
      "group[social]  0.208  0.075   0.087    0.336      0.001    0.001    2711.0   \n",
      "1|study_sigma  0.984  0.300   0.542    1.448      0.011    0.008     836.0   \n",
      "\n",
      "               ess_tail  r_hat  \n",
      "Intercept         667.0    1.0  \n",
      "group[social]    2371.0    1.0  \n",
      "1|study_sigma     764.0    1.0  \n"
     ]
    }
   ],
   "source": [
    "summ = az.summary(\n",
    "    idata_hierarchical,\n",
    "    var_names=[\"Intercept\", \"group\", \"1|study_sigma\"],\n",
    "    hdi_prob=0.90\n",
    ")\n",
    "print(summ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Research Question**  \n",
    "Does the social norm intervention increase towel reuse compared to the control condition?\n",
    "\n",
    "**Hypotheses**  \n",
    "\n",
    "- **Null hypothesis (H₀):**  \n",
    "  The intervention has no effect.  \n",
    "  Mathematically: `group[social] = 0`.\n",
    "\n",
    "- **Alternative hypothesis (H₁):**  \n",
    "  The intervention is effective. The social norm group shows a higher reuse rate than the control group.  \n",
    "  Mathematically: `group[social] > 0`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "\n",
    "- The posterior probability that the intervention effect is greater than zero is nearly 1.0, \n",
    "  indicating very strong evidence for effectiveness.\n",
    "- The posterior mean of `group[social]` is about 0.21 (log-odds), with a 90% HDI of [0.09, 0.34].\n",
    "- This corresponds to approximately a 5–6 percentage point increase in towel reuse under the social norm condition compared to control.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
